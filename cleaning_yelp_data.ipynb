{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_music(s):\n",
    "    d = dict()\n",
    "    key_index = 0\n",
    "    value_index = 0\n",
    "    current_index = 0\n",
    "    check = 0\n",
    "    modify = s[1:-1].replace(\"'\",'')\n",
    "    modify = ', '+modify+','\n",
    "    for i in modify:\n",
    "        if i == \":\":\n",
    "            key_index = current_index\n",
    "        elif i == \",\" and check != 0:\n",
    "            d[modify[value_index+2:key_index]] = modify[key_index+2:current_index]\n",
    "            value_index = current_index\n",
    "        check+=1\n",
    "    \n",
    "        current_index += 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1811/192609 [00:00<00:20, 9216.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data in the business dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192609/192609 [00:20<00:00, 9543.34it/s] \n"
     ]
    }
   ],
   "source": [
    "    # setup an array for writing each row in the csv file\n",
    "    rows = []\n",
    "    # extract fields from business json data set #\n",
    "    # setup an array for storing each json entry\n",
    "    business_data = []\n",
    "    # setup an array for headers we are not using strictly\n",
    "    business_header_removals = ['attributes', 'categories', 'hours', 'neighborhoods', 'open']\n",
    "    # setup an array for headers we are adding\n",
    "    business_header_additions = [\n",
    "    'Sunday_Open', 'Sunday_Close', 'Monday_Open', 'Monday_Close', 'Tuesday_Open','Tuesday_Close', 'Wednesday_Open', \n",
    "    'Wednesday_Close', 'Thursday_Open','Thursday_Close', 'Friday_Open', 'Friday_Close', 'Saturday_Open', \n",
    "    'Saturday_Close','Noise Level', 'Attire', 'Alcohol', 'Price_Range', 'Delivery', 'Outdoor_Seating','Drive-Thru', \n",
    "    'Good_for_Groups', 'Has_TV', 'Caters', 'Waiter_Service','Good_for_Kids', 'Accepts_Credit_Cards', \n",
    "    'Takes_Reservations', 'Wi_Fi', 'Happy_Hour','Good_for_Dancing', 'Smoking', 'BYOB', 'Corkage', 'Take_Out', \n",
    "    'Coat_Check','Parking_Street', 'Parking_Valet', 'Parking_Lot', 'Parking_Garage','Parking_Validated', 'Music_DJ', \n",
    "    'Music_Karaoke', 'Music_Video', 'Music_Live','Music_Jukebox', 'Music_Background_Music', 'Is_Restaurants', \n",
    "    'Sandwiches', 'Fast Food','Nightlife', 'Pizza', 'Bars', 'Mexican', 'Food', 'American (Traditional)','Burgers',\n",
    "    'Chinese', 'Italian', 'American (New)', 'Breakfast & Brunch', 'Thai','Indian', 'Sushi Bars', 'Korean',\n",
    "    'Mediterranean', 'Japanese', 'Seafood', 'Middle Eastern', 'Pakistani', 'Barbeque', 'Vietnamese', 'Asian Fusion',\n",
    "    'Diners','Greek', 'Vegetarian']\n",
    "    # open the business source file\n",
    "    with open('yelp_dataset/business.json') as f:\n",
    "        # for each line in the json file\n",
    "        for line in f:\n",
    "            # store the line in the array for manipulation\n",
    "            business_data.append(json.loads(line))\n",
    "    # close the reader\n",
    "    f.close()\n",
    "    # append the initial keys as csv headers\n",
    "    header = sorted(business_data[0].keys())\n",
    "    # remove keys from the business data that we are not using strictly\n",
    "    for headers in business_header_removals:\n",
    "        if headers in header:\n",
    "            header.remove(headers)\n",
    "    # append the additional business related csv headers\n",
    "    for headers in business_header_additions:\n",
    "        header.append(headers)\n",
    "    print('processing data in the business dataset...')\n",
    "    # for every entry in the business data array\n",
    "    for entry in tqdm(range(0, len(business_data))):\n",
    "        row = []\n",
    "        row.append(business_data[entry]['address'])\n",
    "        row.append(business_data[entry]['business_id'])\n",
    "        row.append(business_data[entry]['city'])\n",
    "        row.append(business_data[entry]['is_open'])\n",
    "        row.append(business_data[entry]['latitude'])\n",
    "        row.append(business_data[entry]['longitude'])\n",
    "        row.append(business_data[entry]['name'])\n",
    "        row.append(business_data[entry]['postal_code'])\n",
    "        row.append(business_data[entry]['review_count'])\n",
    "        row.append(business_data[entry]['stars'])\n",
    "        row.append(business_data[entry]['state'])\n",
    "\n",
    "        \n",
    "        # set up an array for the days of the week\n",
    "        days_of_week = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "        # iterate through the days of the week to extract the open and close times\n",
    "        for time in days_of_week:\n",
    "            # if a time is available\n",
    "            if business_data[entry]['hours'] != None and time in business_data[entry]['hours']:\n",
    "                index0 = business_data[entry]['hours'][time].find(\":\")\n",
    "                index = business_data[entry]['hours'][time].find(\"-\")\n",
    "                # append the open time\n",
    "                open_time = business_data[entry]['hours'][time][0:index0]\n",
    "                row.append(int(open_time))\n",
    "                # append the closing time\n",
    "                close_time = business_data[entry]['hours'][time][index:index+2]\n",
    "                close_time = close_time.replace(\"-\",'')\n",
    "                row.append(int(close_time))\n",
    "            # else if a time is not available\n",
    "            else:\n",
    "                # append NA for the open time\n",
    "                row.append(0)\n",
    "                # append NA for the closing time\n",
    "                row.append(0)\n",
    "\n",
    "        # extract the attributes of interest\n",
    "        attributes = ['Noise Level', 'Attire', 'Alcohol', 'Price Range', 'Delivery', 'Outdoor Seating', 'Drive-Thru',\n",
    "                      'Good For Groups', 'Has TV', 'Caters', 'Waiter Service', 'Good for Kids', 'Accepts Credit Cards',\n",
    "                      'Takes Reservations', 'Wi-Fi', 'Happy Hour', 'Good For Dancing', 'Smoking', 'BYOB', 'Corkage',\n",
    "                      'Take-out', 'Coat Check']\n",
    "        # for each attribute that is not nested\n",
    "        for attribute in attributes:\n",
    "            # if there is an attribute\n",
    "            if business_data[entry]['attributes']!= None and attribute in business_data[entry]['attributes']:\n",
    "                # if the attribute contains true\n",
    "                if business_data[entry]['attributes'][attribute] is True:\n",
    "                    row.append(1)\n",
    "                # else if the attribute contains false\n",
    "                elif business_data[entry]['attributes'][attribute] is False:\n",
    "                    row.append(0)\n",
    "                # else if the attribute is non-empty and not true of false\n",
    "                elif business_data[entry]['attributes'][attribute] is not None:\n",
    "                    row.append(business_data[entry]['attributes'][attribute])\n",
    "            # else of the attribute is not available\n",
    "            else:\n",
    "                # append NA for the attribute\n",
    "                row.append('NA')\n",
    "        # extract the parking attributes\n",
    "        \n",
    "        \n",
    "    \n",
    "        parking_attributes = ['street', 'valet', 'lot', 'garage', 'validated']\n",
    "        # for each parking attribute\n",
    "        for attribute in parking_attributes:\n",
    "            # if there are parking attributes\n",
    "            if business_data[entry]['attributes'] != None and 'Parking' in business_data[entry]['attributes']:\n",
    "                # if the parking attribute exists\n",
    "                if attribute in business_data[entry]['attributes']['Parking']:\n",
    "                    # if the parking attribute is true\n",
    "                    if business_data[entry]['attributes']['Parking'][attribute] is True:\n",
    "                        row.append(1)\n",
    "                    # if the parking attribute is false\n",
    "                    elif business_data[entry]['attributes']['Parking'][attribute] is False:\n",
    "                        row.append(0)\n",
    "                    # note that the parking attributes are all true/false so no need for is not None elif\n",
    "                # else if the specific attribute is not available\n",
    "                else:\n",
    "                    row.append(0.5)\n",
    "            # else if the parking attribute is not available\n",
    "            else:\n",
    "                row.append(0)\n",
    "        # extract the music attributes\n",
    "        music_attributes = ['dj', 'karaoke', 'video', 'live', 'jukebox', 'background_music']\n",
    "        # for each music attribute\n",
    "        for attribute in music_attributes:\n",
    "            # if there are music attributes\n",
    "            if business_data[entry]['attributes'] != None and 'Music' in business_data[entry]['attributes']:\n",
    "                # if the music attribute exists\n",
    "                d = modify_music(business_data[entry]['attributes']['Music'])\n",
    "                if attribute in business_data[entry]['attributes']['Music']:\n",
    "                    # if the music attribute is true\n",
    "                    if d[attribute] == 'True':\n",
    "                        row.append(1)\n",
    "                    # if the music attribute is false\n",
    "                    elif d[attribute] == 'False':\n",
    "                        row.append(0)\n",
    "                    # note that the music attributes are all true/false so no need for is not None elif\n",
    "                # else if the specific attribute is not available\n",
    "                else:\n",
    "                    row.append(0.5)\n",
    "            # else if the music attribute is not available\n",
    "            else:\n",
    "                row.append(0)\n",
    "\n",
    "        # extract the categories\n",
    "        categories_of_interest = ['Restaurants', 'Sandwiches', 'Fast Food', 'Nightlife', 'Pizza', 'Bars', 'Mexican',\n",
    "                                  'Food', 'American (Traditional)', 'Burgers', 'Chinese', 'Italian',\n",
    "                                  'American (New)', 'Breakfast & Brunch', 'Thai', 'Indian', 'Sushi Bars', 'Korean',\n",
    "                                  'Mediterranean', 'Japanese', 'Seafood', 'Middle Eastern', 'Pakistani', 'Barbeque',\n",
    "                                  'Vietnamese', 'Asian Fusion', 'Diners', 'Greek', 'Vegetarian']\n",
    "        # for each category of interest\n",
    "        for category in categories_of_interest:\n",
    "            # if the category is in the category entry\n",
    "            if business_data[entry]['categories'] != None and category in business_data[entry]['categories']:\n",
    "                row.append(1)\n",
    "            # else if the category is not in the entry\n",
    "            else:\n",
    "                row.append(0)\n",
    "        # remove stray text, such as \"\\n\" form address\n",
    "        # set up an array for the cleaned row entries\n",
    "        row_clean = []\n",
    "        # for every item in the row\n",
    "        for item in row:\n",
    "            # scan and replace for nasty text\n",
    "            row_clean.append(str(item).replace('\\n', ' '))\n",
    "        # after all fields have been extracted and cleaned, append the row to the rows array for writing to csv\n",
    "        rows.append(row_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 192609/192609 [00:01<00:00, 108485.41it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('yelp.csv', 'w') as out:\n",
    "    writer = csv.writer(out)\n",
    "    writer.writerow(header)\n",
    "    for entry in tqdm(range(0, len(rows))):\n",
    "        try:\n",
    "            writer.writerow(rows[entry])\n",
    "        except UnicodeEncodeError:\n",
    "            continue\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
